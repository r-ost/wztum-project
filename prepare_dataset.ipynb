{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86903680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchaudio\n",
    "import os\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "\n",
    "from AudioWaveformDataset import AudioWaveformDataset\n",
    "from WaveformAugmentations import WaveformAugmentations\n",
    "from SpectrogramAugmentations import SpectrogramAugmentations\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "UNKNOWNS_COUNT = 2400 # average number of examples per class in the dataset (based on EDA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_background_waveforms(background_noise_dir='data/train/audio/_background_noise_'):\n",
    "    background_waveforms = []\n",
    "    for file in os.listdir(background_noise_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            try:\n",
    "                path = os.path.join(background_noise_dir, file)\n",
    "                waveform, sr = torchaudio.load(path)\n",
    "                waveform = waveform.squeeze(0)  # remove channel dimension\n",
    "                if sr != SAMPLE_RATE:\n",
    "                    resampler = T.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "                    waveform = resampler(waveform)\n",
    "                background_waveforms.append(waveform)\n",
    "                print(f\"Loaded background: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    return background_waveforms\n",
    "\n",
    "def generate_silence_waveforms(background_waveforms, count, duration=1.0, sample_rate=SAMPLE_RATE):\n",
    "    silence_waveforms = []\n",
    "    for _ in range(count):\n",
    "        bg_waveform = random.choice(background_waveforms)\n",
    "        start = random.randint(0, bg_waveform.size(0) - int(duration * sample_rate))\n",
    "        silence_waveform = bg_waveform[start:start + int(duration * sample_rate)]\n",
    "        silence_waveforms.append(silence_waveform)\n",
    "    return silence_waveforms\n",
    "\n",
    "def waveform_augmentation_pipeline(sample_rate, background_waveforms=None, rir_waveforms=None, p=0.5):\n",
    "    def augment_waveform(waveform):\n",
    "        augmented = waveform\n",
    "        if random.random() < p:\n",
    "            augmented = WaveformAugmentations.time_shift(augmented)\n",
    "        \n",
    "        if random.random() < p:\n",
    "            augmented = WaveformAugmentations.add_noise(augmented, noise_level=random.uniform(0.001, 0.005))\n",
    "        \n",
    "        if random.random() < p:\n",
    "            augmented = WaveformAugmentations.pitch_shift(augmented, sample_rate)\n",
    "        \n",
    "        if random.random() < p:\n",
    "            augmented = WaveformAugmentations.volume_control(augmented)\n",
    "        \n",
    "        if random.random() < p*0.6:\n",
    "            augmented = WaveformAugmentations.speed_change(augmented, sample_rate)\n",
    "            \n",
    "        if random.random() < p*0.6:\n",
    "            augmented = WaveformAugmentations.reverb(augmented, sample_rate)\n",
    "        \n",
    "        if background_waveforms and random.random() < p*0.8:\n",
    "            bg_waveform = random.choice(background_waveforms)\n",
    "            augmented = WaveformAugmentations.mix_background(augmented, bg_waveform)\n",
    "        \n",
    "        if rir_waveforms and random.random() < p*0.6:\n",
    "            rir_waveform = random.choice(rir_waveforms)\n",
    "            augmented = WaveformAugmentations.convolution_reverb(augmented, rir_waveform)\n",
    "            \n",
    "        return augmented\n",
    "    return augment_waveform\n",
    "\n",
    "def spectrogram_augmentation_pipeline(p=0.5):\n",
    "    def augment_spectrogram(spectrogram):\n",
    "        augmented = spectrogram\n",
    "        if random.random() < p:\n",
    "            time_mask_param = random.randint(5, 20)\n",
    "            augmented = SpectrogramAugmentations.time_masking(augmented, time_mask_param)\n",
    "        \n",
    "        if random.random() < p:\n",
    "            freq_mask_param = random.randint(5, 15)\n",
    "            augmented = SpectrogramAugmentations.freq_masking(augmented, freq_mask_param)\n",
    "        return augmented\n",
    "    \n",
    "    return augment_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56927f42",
   "metadata": {},
   "source": [
    "Test waveform augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e14e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_waveforms = load_background_waveforms()\n",
    "augmentation_pipeline = waveform_augmentation_pipeline(sample_rate=SAMPLE_RATE, p=0.2)\n",
    "\n",
    "wav_path = r\"data\\train\\audio\\yes\\0c2ca723_nohash_0.wav\"\n",
    "waveform, sample_rate = torchaudio.load(wav_path)\n",
    "waveform = waveform.squeeze(0)  # remove channel dimension\n",
    "Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd971c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_waveform = augmentation_pipeline(waveform)\n",
    "Audio(augmented_waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a17dd",
   "metadata": {},
   "source": [
    "Test spectrogram augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8af16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = T.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=64,\n",
    ")\n",
    "db_transform = T.AmplitudeToDB()\n",
    "\n",
    "spectrogram = mel_spectrogram(waveform)\n",
    "spectrogram = db_transform(spectrogram)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(spectrogram.squeeze().numpy(), origin=\"lower\", aspect=\"auto\", cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40885d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_spectrogram = spectrogram_augmentation_pipeline(1.0)(spectrogram)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(augmented_spectrogram.squeeze().numpy(), origin=\"lower\", aspect=\"auto\", cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284060ef",
   "metadata": {},
   "source": [
    "## Run data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_augmentation(\n",
    "    audio_dir, \n",
    "    output_dir,\n",
    "    sample_rate=16000,\n",
    "    n_mels=64,\n",
    "    n_fft=400,\n",
    "    hop_length=200,\n",
    "    augment_probability=0.5,\n",
    "    max_augmented_copies=1,  # Number of augmented copies to generate per original sample\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    background_waveforms = load_background_waveforms()\n",
    "    waveform_augment_fn = waveform_augmentation_pipeline(\n",
    "        sample_rate, \n",
    "        background_waveforms, \n",
    "        p=augment_probability)\n",
    "    spec_augment_fn = spectrogram_augmentation_pipeline(p=augment_probability / 2)\n",
    "    \n",
    "    mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "    db_transform = T.AmplitudeToDB()\n",
    "    \n",
    "    # Add silence examples\n",
    "    silence_waveforms = generate_silence_waveforms(\n",
    "        background_waveforms, \n",
    "        count=UNKNOWNS_COUNT, \n",
    "        duration=1.0, \n",
    "        sample_rate=sample_rate)\n",
    "    silence_dir = os.path.join(audio_dir, 'silence')\n",
    "    os.makedirs(silence_dir, exist_ok=True)\n",
    "    for i, silence_waveform in enumerate(silence_waveforms):\n",
    "        silence_path = os.path.join(silence_dir, f'silence_{i}.wav')\n",
    "        torchaudio.save(silence_path, silence_waveform.unsqueeze(0), sample_rate=sample_rate)\n",
    "    \n",
    "    dataset = AudioWaveformDataset(audio_dir)\n",
    "    print(f\"Processing {len(dataset)} audio files...\")\n",
    "    \n",
    "    l = list(zip(dataset.filepaths, dataset.labels))\n",
    "    random.shuffle(l)\n",
    "    unknowns_count = 0\n",
    "    for audio_file, label_idx in tqdm(l, desc=\"Processing audio files\"):\n",
    "        label = dataset.idx2label[label_idx]\n",
    "        if label == 'unknown' and unknowns_count >= UNKNOWNS_COUNT:\n",
    "            continue\n",
    "        elif label == 'unknown':\n",
    "            unknowns_count += 1\n",
    "\n",
    "        # Load audio\n",
    "        waveform, orig_sr = torchaudio.load(audio_file)\n",
    "        waveform = waveform.squeeze(0)  # remove channel dimension\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if orig_sr != sample_rate:\n",
    "            resampler = T.Resample(orig_freq=orig_sr, new_freq=sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Save original spectrogram\n",
    "        spec = mel_spectrogram(waveform)\n",
    "        spec = db_transform(spec)\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(audio_file)[0] + '.pt')\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        torch.save(spec, output_path)\n",
    "        \n",
    "        # Generate augmented versions\n",
    "        augmented_copies = random.randint(0, max_augmented_copies)\n",
    "        for i in range(augmented_copies):\n",
    "            # Apply waveform augmentation\n",
    "            augmented = waveform_augment_fn(waveform)\n",
    "            \n",
    "            # Generate spectrogram for augmented waveform\n",
    "            spectrogram = mel_spectrogram(augmented)\n",
    "            spectrogram = db_transform(spectrogram)\n",
    "            augmented_spectrogram = spec_augment_fn(spectrogram)\n",
    "            \n",
    "            # Save augmented spectrogram with suffix\n",
    "            aug_output_path = os.path.join(\n",
    "                output_dir, \n",
    "                os.path.splitext(audio_file)[0] + f'_aug{i+1}.pt'\n",
    "            )\n",
    "            os.makedirs(os.path.dirname(aug_output_path), exist_ok=True)\n",
    "            torch.save(augmented_spectrogram, aug_output_path)\n",
    "    \n",
    "    print(f\"All spectrograms saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = preprocess_with_augmentation(\n",
    "    audio_dir=\"data/train/audio\", \n",
    "    output_dir=\"data/train/spectrograms\",\n",
    "    augment_probability=0.1,  \n",
    "    max_augmented_copies=1,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
